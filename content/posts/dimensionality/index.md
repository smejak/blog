---
title: Carving up problems at their joints
date: "2023-09-05 10:00:00"
---

Imagine looking at flower. Depending on the lighting conditions and some other factors, you see the flower with different levels of detail. If you take a picture and project it onto a low-resolution screen, instead of a flower you might just see colored boxes that barely capture the flower’s features. On the other hand, if you have a high-resolution screen, you might not be able to tell the difference between the real flower and the one projected on your screen, nevertheless by looking at the screen, you acknowledge you’re not actually looking at a flower but rather on a set of colored pixels. Of course, this is not an exhaustive set of the possibilities for perceiving a flower. If you put that flower under a microscope, you’d start seeing individual cells that make up the flower’s structure. At that point, you might not even know that what you’re looking at is indeed a flower, even though you now perceive at a  resolution much higher than that of your naked eye. Go further still and you might start seeing the smaller structures making up the cells, and at the limit of technological abilities, you might even glimpse at individual molecules and the atoms that make them up. And to complete this particular spectrum of resolutions, imagine going farther away from the flower. The farther you get, the smaller it is and the less detail you see, similarly as with the picture on the low-resolution screen, but also fundamentally different, since what you’re seeing should still be called a flower rather than a set of pixels. Go far enough, and you’ll just see a dot that is indistinguishable from anything else at that distance, so even though you may “know” that you’re looking at a flower, your ability to recognize that it is a flower is perhaps worse than when you were looking at the picture on the low-resolution screen.

Perceived information is contextual, both on the particular apparatus through which it is presented and through our own beliefs about what we expect to see. Furthermore, we can never fully capture the *thing* with just semantics. You know you’re still looking at a flower, even though you just see a red dot in the distance. The problem of resolution and semantics is present in every other piece of information that we can perceive or think about. And of course, considering the map-territory fallacy, no description or even perception of the flower is *what the flower is*, assuming we can even say that something *is* in the first place without introducing a coarse-graining model of it. The problem of communicating information about some other thing other than what the information is, therefore, is an intricate control/optimization problem in which one tries to capture as much information about that thing without needing the thing itself, while at the same time trying to balance other things, such as the energy costs associated with performing the action of describing something (such as hitting the keys on your keyboard).