---
title: CC Intelligence has all the maps (A Thousand Brains part 1)
date: "2021-06-26 13:00:00"
---

I’m currently reading a book titled *A Thousand Brains* by Jeff Hawkins. I can’t stress this enough: one of the best books I’ve ever read. I am writing this post now as I want to make this a two-part thing, so now that the first half is still very fresh in my brain, let’s get into it. Also, spoiler alert, I won’t be as eloquent as Jeff in my writing, but I am going to talk about the contents.

I believe neuroscience and artificial intelligence will inevitably become the two most impactful fields of study, quite literally impacting the future of our entire civilization. Why? There may be many answers, but for me, the reason is quite simple. As we answer more problems, we realize there are harder and harder problems for us to solve. At some point, it inevitably needs to be easier to solve the problem of intelligence and create something that is capable of solving the problems we could not. There may be some existential implications in that, but I won’t get into that right now. In his book, Jeff Hawkins introduces the Thousand Brains Theory, which I think is most easily described as *Special Brain Relativity*. The main idea behind the theory is that the neocortex (the part of the brain responsible for our human intelligence), is made up of thousands of so-called cortical columns, and each of these columns learns hundreds of models of objects through the use of reference frames (that’s where my association with relativity came from). Jeff suggests that cortical columns make use of two types of cells, called place cells and grid cells, which can typically be found in the hippocampus and the entorhinal cortex, respectively (two parts of the old brain). In the old brain, these cells create maps of our physical world, allowing us to navigate our environment and remember things like how to find our way back home and which road to take to work. Since the old brain developed over the span of millions of years, it is likely that the neocortex has a simpler, perhaps more flexible variant of the two types of cells, allowing us to create detailed maps of pretty much everything we know. This map-centric thinking actually makes a lot of sense, and explains why stories are so memorable but a random sequence of numbers isn’t. A story is a nicely connected sequence of events (like a grid), and the details within a story are always found at the same place (the big bad wolf ate the grandmother at her house and not anywhere else). In this way, Jeff explains how intelligence is closely linked to movement and how the train of thought is in itself similar to moving. When you solve a physics problem, you need to take a series of steps: identify the problem and the variables, modify some equations to get a general solution, insert numbers to get the answer. On the other hand, if I tell you a random fact in physics, you might forget it instantly unless you already know the context behind it. Essentially, intelligence is both **content** and **context**, or for the sake of a memorable name, let’s say humans operate on CC intelligence (compared to computers which so far only have C intelligence (that unexpectedly turned into a pretty accurate pun)).

Now come the questions. How do we create artificial CC intelligence (or ACCI; the term AGI is too associated with deep neural networks which seem to be quite limited as of right now)? Stay tuned.